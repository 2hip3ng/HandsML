{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4f96de",
   "metadata": {},
   "source": [
    "# 逻辑回归推导与实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec1a0b7",
   "metadata": {},
   "source": [
    "## 1. sigmod 推导"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd6af67",
   "metadata": {},
   "source": [
    "$$ \\begin{align} \n",
    "sigmod(x) &= \\frac{1}{1+e^{-x}} \\\\\n",
    "sigmod'(x) &= \\frac{ \\partial sigmod(x) } { \\partial x} \\\\\n",
    "&= \\frac{\\partial \\frac{1}{1+e^{-x}}} {\\partial x} \\\\\n",
    "&= (-1) * (1+e^{-x})^{-2} * \\frac {\\partial (1+e^{-x})} {\\partial x} \\\\\n",
    "&= (-1) * (1+e^{-x})^{-2} * e^{-x} * (-1) \\\\\n",
    "&= (1+e^{-x})^{-2} * e^{-x} \\\\\n",
    "&= \\frac{1}{1+e^{-x}} * \\frac{e^{-x}}{1+e^{-x}} \\\\\n",
    "&= sigmod(x) * (1-sigmod(x)) \\\\\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0df66fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12845fac0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "def sigmod(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "\n",
    "x = list(range(-10, 10))\n",
    "\n",
    "y = [sigmod(_) for _ in x]\n",
    "z = [sigmod(_)*(1-sigmod(_)) for _ in x]\n",
    "\n",
    "p1 = plt.subplot(121)\n",
    "p1.plot(x, y)\n",
    "\n",
    "p2 = plt.subplot(122)\n",
    "p2.plot(x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e226e871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d172fabf",
   "metadata": {},
   "source": [
    "## 2 逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cbeaef",
   "metadata": {},
   "source": [
    "#### a) forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e55255",
   "metadata": {},
   "source": [
    "$$ h(x) = sigmod(w^Tx) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9ec28a",
   "metadata": {},
   "source": [
    "x, w 为列向量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38fbece",
   "metadata": {},
   "source": [
    " #### b) loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af5aefe",
   "metadata": {},
   "source": [
    "$$ loss = -[ylog(h(x))+(1-y)log(1-h(x))] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1972cae7",
   "metadata": {},
   "source": [
    "以单个样本为例的交叉熵公式，mini-batch版加入求和即可；y 为 0， 1 标签"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d29e4e",
   "metadata": {},
   "source": [
    "#### c) backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fecaa32",
   "metadata": {},
   "source": [
    "$$ \\begin{align}\n",
    "\\frac{\\partial h(x)}{\\partial w} &= sigmod(w^Tx) * (1-sigmod(w^Tx)) * x \\\\\n",
    "&= h(x) * (1-h(x)) * x\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de2857",
   "metadata": {},
   "source": [
    "$$ \\begin{align}\n",
    "\\frac {\\partial loss} {\\partial w} &= -[y* \\frac{1}{h(x)}* \\frac{\\partial h(x)}{ \\partial w} + (1-y) * \\frac{1}{1-h(x)}*(-1)* \\frac{\\partial h(x)}{ \\partial w}] \\\\\n",
    "&= -[y* \\frac{1}{h(x)} + (y-1) * \\frac{1}{1-h(x)}] * \\frac{\\partial h(x)}{ \\partial w} \\\\\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f866c88d",
   "metadata": {},
   "source": [
    "$$ \\begin{align}\n",
    "\\frac {\\partial loss} {\\partial w} &= -[y* \\frac{1}{h(x)} + (y-1) * \\frac{1}{1-h(x)}] * h(x) * (1-h(x)) * x \\\\\n",
    "&= -[y*(1-h(x))  + (y-1) * h(x)]  * x \\\\\n",
    "&= -[y - h(x)] * x \\\\\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc871c",
   "metadata": {},
   "source": [
    "#### d) 推广至batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b11ea",
   "metadata": {},
   "source": [
    "$$ \\begin{align}\n",
    "\\frac {\\partial loss} {\\partial w} &= - \\frac{1}{N} \\sum_{i=1}^{N} {[y_i - h(x_i)] * x_i} \\\\\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720011ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c42986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32ae495b",
   "metadata": {},
   "source": [
    "## 3 numpy 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b04ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "dd43076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR:\n",
    "    def __init__(self, input_dim):\n",
    "        self.W = np.zeros((1, input_dim))\n",
    "        self.b = 0\n",
    "        self.learning_rate = 0\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        sigmoid function\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        sigmoid derivative funciton\n",
    "        \"\"\"\n",
    "        return sigmoid(x) * (1 - sigmoid(x))\n",
    "    \n",
    "    def loss_function(self, y, p):\n",
    "        \"\"\"\n",
    "        calcute the loss between true labels and preds using cross-entroy\n",
    "        y: true labels\n",
    "        p: preds\n",
    "        \"\"\"\n",
    "        return -1 / len(y) * (np.dot(y.T, np.log(p)) + np.dot((1-y).T, np.log(1-p)))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X: m*n m为样本数量，n为特征维度\n",
    "        \"\"\"\n",
    "        # self.W 1*n，n为特征维度\n",
    "        z = np.dot(X, self.W.T) + self.b # m*1\n",
    "        a = self.sigmoid(z)\n",
    "\n",
    "        return a\n",
    "    \n",
    "    def backward(self, X, y, p):\n",
    "        \"\"\"\n",
    "        X: m*n\n",
    "        y: m*1\n",
    "        p: m*1\n",
    "        \"\"\"\n",
    "        loss = self.loss_function(y, p)\n",
    "        dw = -1/len(y)*np.dot((y-p).T, X)\n",
    "        db = -1/len(y)*np.sum(y-p)\n",
    "        \n",
    "        self.W = self.W - self.learning_rate * dw\n",
    "        self.b = self.b - self.learning_rate * db\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def fit(self, train_data, train_labels, epochs=1000, batch_size=64, learning_rate=1):\n",
    "        \"\"\"\n",
    "        fit the model using minibatch gradient descent\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        m, n = train_data.shape\n",
    "        \n",
    "        assert m == train_labels.shape[0]\n",
    "        \n",
    "        batch_num = int(m/batch_size)+1\n",
    "        for epoch in range(epochs):\n",
    "            for bn in range(batch_num):\n",
    "                start = bn * batch_size\n",
    "                end = start + batch_size\n",
    "                \n",
    "                if start >= m:\n",
    "                    break\n",
    "                if end >= m:\n",
    "                    end = m\n",
    "                X = train_data[start:end]\n",
    "                y = train_labels[start:end]\n",
    "                \n",
    "                p = self.forward(X)\n",
    "                \n",
    "                loss = self.backward(X, y, p)\n",
    "                \n",
    "                print(\"epoch: {}, batch_num: {} loss: {}\".format(epoch, bn, loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "77eee04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "347be6cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_num: 0 loss: [[0.69314718]]\n",
      "epoch: 1, batch_num: 0 loss: [[0.57593942]]\n",
      "epoch: 2, batch_num: 0 loss: [[0.48592791]]\n",
      "epoch: 3, batch_num: 0 loss: [[0.41617735]]\n",
      "epoch: 4, batch_num: 0 loss: [[0.36142023]]\n",
      "epoch: 5, batch_num: 0 loss: [[0.3178012]]\n",
      "epoch: 6, batch_num: 0 loss: [[0.28253777]]\n",
      "epoch: 7, batch_num: 0 loss: [[0.25362299]]\n",
      "epoch: 8, batch_num: 0 loss: [[0.2295994]]\n",
      "epoch: 9, batch_num: 0 loss: [[0.20939709]]\n",
      "epoch: 10, batch_num: 0 loss: [[0.19222074]]\n",
      "epoch: 11, batch_num: 0 loss: [[0.17747124]]\n",
      "epoch: 12, batch_num: 0 loss: [[0.16469136]]\n",
      "epoch: 13, batch_num: 0 loss: [[0.15352765]]\n",
      "epoch: 14, batch_num: 0 loss: [[0.1437036]]\n",
      "epoch: 15, batch_num: 0 loss: [[0.1350004]]\n",
      "epoch: 16, batch_num: 0 loss: [[0.12724303]]\n",
      "epoch: 17, batch_num: 0 loss: [[0.12029017]]\n",
      "epoch: 18, batch_num: 0 loss: [[0.11402656]]\n",
      "epoch: 19, batch_num: 0 loss: [[0.10835746]]\n",
      "epoch: 20, batch_num: 0 loss: [[0.10320434]]\n",
      "epoch: 21, batch_num: 0 loss: [[0.09850163]]\n",
      "epoch: 22, batch_num: 0 loss: [[0.09419419]]\n",
      "epoch: 23, batch_num: 0 loss: [[0.09023536]]\n",
      "epoch: 24, batch_num: 0 loss: [[0.08658541]]\n",
      "epoch: 25, batch_num: 0 loss: [[0.08321032]]\n",
      "epoch: 26, batch_num: 0 loss: [[0.0800808]]\n",
      "epoch: 27, batch_num: 0 loss: [[0.07717154]]\n",
      "epoch: 28, batch_num: 0 loss: [[0.07446051]]\n",
      "epoch: 29, batch_num: 0 loss: [[0.07192849]]\n",
      "epoch: 30, batch_num: 0 loss: [[0.06955863]]\n",
      "epoch: 31, batch_num: 0 loss: [[0.06733611]]\n",
      "epoch: 32, batch_num: 0 loss: [[0.06524783]]\n",
      "epoch: 33, batch_num: 0 loss: [[0.06328218]]\n",
      "epoch: 34, batch_num: 0 loss: [[0.06142884]]\n",
      "epoch: 35, batch_num: 0 loss: [[0.05967859]]\n",
      "epoch: 36, batch_num: 0 loss: [[0.05802319]]\n",
      "epoch: 37, batch_num: 0 loss: [[0.05645525]]\n",
      "epoch: 38, batch_num: 0 loss: [[0.0549681]]\n",
      "epoch: 39, batch_num: 0 loss: [[0.05355576]]\n",
      "epoch: 40, batch_num: 0 loss: [[0.05221278]]\n",
      "epoch: 41, batch_num: 0 loss: [[0.05093424]]\n",
      "epoch: 42, batch_num: 0 loss: [[0.04971568]]\n",
      "epoch: 43, batch_num: 0 loss: [[0.04855302]]\n",
      "epoch: 44, batch_num: 0 loss: [[0.04744255]]\n",
      "epoch: 45, batch_num: 0 loss: [[0.04638088]]\n",
      "epoch: 46, batch_num: 0 loss: [[0.04536488]]\n",
      "epoch: 47, batch_num: 0 loss: [[0.04439171]]\n",
      "epoch: 48, batch_num: 0 loss: [[0.04345875]]\n",
      "epoch: 49, batch_num: 0 loss: [[0.04256359]]\n",
      "epoch: 50, batch_num: 0 loss: [[0.04170399]]\n",
      "epoch: 51, batch_num: 0 loss: [[0.04087789]]\n",
      "epoch: 52, batch_num: 0 loss: [[0.04008341]]\n",
      "epoch: 53, batch_num: 0 loss: [[0.03931877]]\n",
      "epoch: 54, batch_num: 0 loss: [[0.03858234]]\n",
      "epoch: 55, batch_num: 0 loss: [[0.03787261]]\n",
      "epoch: 56, batch_num: 0 loss: [[0.03718815]]\n",
      "epoch: 57, batch_num: 0 loss: [[0.03652766]]\n",
      "epoch: 58, batch_num: 0 loss: [[0.03588992]]\n",
      "epoch: 59, batch_num: 0 loss: [[0.03527377]]\n",
      "epoch: 60, batch_num: 0 loss: [[0.03467815]]\n",
      "epoch: 61, batch_num: 0 loss: [[0.03410205]]\n",
      "epoch: 62, batch_num: 0 loss: [[0.03354454]]\n",
      "epoch: 63, batch_num: 0 loss: [[0.03300475]]\n",
      "epoch: 64, batch_num: 0 loss: [[0.03248185]]\n",
      "epoch: 65, batch_num: 0 loss: [[0.03197506]]\n",
      "epoch: 66, batch_num: 0 loss: [[0.03148366]]\n",
      "epoch: 67, batch_num: 0 loss: [[0.03100696]]\n",
      "epoch: 68, batch_num: 0 loss: [[0.03054431]]\n",
      "epoch: 69, batch_num: 0 loss: [[0.03009512]]\n",
      "epoch: 70, batch_num: 0 loss: [[0.0296588]]\n",
      "epoch: 71, batch_num: 0 loss: [[0.02923481]]\n",
      "epoch: 72, batch_num: 0 loss: [[0.02882265]]\n",
      "epoch: 73, batch_num: 0 loss: [[0.02842182]]\n",
      "epoch: 74, batch_num: 0 loss: [[0.02803187]]\n",
      "epoch: 75, batch_num: 0 loss: [[0.02765237]]\n",
      "epoch: 76, batch_num: 0 loss: [[0.02728291]]\n",
      "epoch: 77, batch_num: 0 loss: [[0.02692308]]\n",
      "epoch: 78, batch_num: 0 loss: [[0.02657253]]\n",
      "epoch: 79, batch_num: 0 loss: [[0.02623091]]\n",
      "epoch: 80, batch_num: 0 loss: [[0.02589787]]\n",
      "epoch: 81, batch_num: 0 loss: [[0.0255731]]\n",
      "epoch: 82, batch_num: 0 loss: [[0.0252563]]\n",
      "epoch: 83, batch_num: 0 loss: [[0.02494718]]\n",
      "epoch: 84, batch_num: 0 loss: [[0.02464547]]\n",
      "epoch: 85, batch_num: 0 loss: [[0.0243509]]\n",
      "epoch: 86, batch_num: 0 loss: [[0.02406323]]\n",
      "epoch: 87, batch_num: 0 loss: [[0.02378221]]\n",
      "epoch: 88, batch_num: 0 loss: [[0.02350763]]\n",
      "epoch: 89, batch_num: 0 loss: [[0.02323926]]\n",
      "epoch: 90, batch_num: 0 loss: [[0.02297689]]\n",
      "epoch: 91, batch_num: 0 loss: [[0.02272033]]\n",
      "epoch: 92, batch_num: 0 loss: [[0.02246939]]\n",
      "epoch: 93, batch_num: 0 loss: [[0.02222389]]\n",
      "epoch: 94, batch_num: 0 loss: [[0.02198365]]\n",
      "epoch: 95, batch_num: 0 loss: [[0.02174851]]\n",
      "epoch: 96, batch_num: 0 loss: [[0.0215183]]\n",
      "epoch: 97, batch_num: 0 loss: [[0.02129288]]\n",
      "epoch: 98, batch_num: 0 loss: [[0.0210721]]\n",
      "epoch: 99, batch_num: 0 loss: [[0.02085581]]\n",
      "epoch: 100, batch_num: 0 loss: [[0.02064388]]\n",
      "epoch: 101, batch_num: 0 loss: [[0.02043618]]\n",
      "epoch: 102, batch_num: 0 loss: [[0.02023259]]\n",
      "epoch: 103, batch_num: 0 loss: [[0.02003298]]\n",
      "epoch: 104, batch_num: 0 loss: [[0.01983725]]\n",
      "epoch: 105, batch_num: 0 loss: [[0.01964528]]\n",
      "epoch: 106, batch_num: 0 loss: [[0.01945695]]\n",
      "epoch: 107, batch_num: 0 loss: [[0.01927218]]\n",
      "epoch: 108, batch_num: 0 loss: [[0.01909086]]\n",
      "epoch: 109, batch_num: 0 loss: [[0.0189129]]\n",
      "epoch: 110, batch_num: 0 loss: [[0.0187382]]\n",
      "epoch: 111, batch_num: 0 loss: [[0.01856668]]\n",
      "epoch: 112, batch_num: 0 loss: [[0.01839824]]\n",
      "epoch: 113, batch_num: 0 loss: [[0.01823282]]\n",
      "epoch: 114, batch_num: 0 loss: [[0.01807032]]\n",
      "epoch: 115, batch_num: 0 loss: [[0.01791068]]\n",
      "epoch: 116, batch_num: 0 loss: [[0.01775381]]\n",
      "epoch: 117, batch_num: 0 loss: [[0.01759965]]\n",
      "epoch: 118, batch_num: 0 loss: [[0.01744812]]\n",
      "epoch: 119, batch_num: 0 loss: [[0.01729916]]\n",
      "epoch: 120, batch_num: 0 loss: [[0.01715271]]\n",
      "epoch: 121, batch_num: 0 loss: [[0.01700871]]\n",
      "epoch: 122, batch_num: 0 loss: [[0.01686708]]\n",
      "epoch: 123, batch_num: 0 loss: [[0.01672778]]\n",
      "epoch: 124, batch_num: 0 loss: [[0.01659075]]\n",
      "epoch: 125, batch_num: 0 loss: [[0.01645593]]\n",
      "epoch: 126, batch_num: 0 loss: [[0.01632327]]\n",
      "epoch: 127, batch_num: 0 loss: [[0.01619272]]\n",
      "epoch: 128, batch_num: 0 loss: [[0.01606423]]\n",
      "epoch: 129, batch_num: 0 loss: [[0.01593775]]\n",
      "epoch: 130, batch_num: 0 loss: [[0.01581324]]\n",
      "epoch: 131, batch_num: 0 loss: [[0.01569064]]\n",
      "epoch: 132, batch_num: 0 loss: [[0.01556992]]\n",
      "epoch: 133, batch_num: 0 loss: [[0.01545103]]\n",
      "epoch: 134, batch_num: 0 loss: [[0.01533394]]\n",
      "epoch: 135, batch_num: 0 loss: [[0.01521859]]\n",
      "epoch: 136, batch_num: 0 loss: [[0.01510496]]\n",
      "epoch: 137, batch_num: 0 loss: [[0.014993]]\n",
      "epoch: 138, batch_num: 0 loss: [[0.01488268]]\n",
      "epoch: 139, batch_num: 0 loss: [[0.01477396]]\n",
      "epoch: 140, batch_num: 0 loss: [[0.01466681]]\n",
      "epoch: 141, batch_num: 0 loss: [[0.0145612]]\n",
      "epoch: 142, batch_num: 0 loss: [[0.01445709]]\n",
      "epoch: 143, batch_num: 0 loss: [[0.01435445]]\n",
      "epoch: 144, batch_num: 0 loss: [[0.01425324]]\n",
      "epoch: 145, batch_num: 0 loss: [[0.01415345]]\n",
      "epoch: 146, batch_num: 0 loss: [[0.01405504]]\n",
      "epoch: 147, batch_num: 0 loss: [[0.01395798]]\n",
      "epoch: 148, batch_num: 0 loss: [[0.01386224]]\n",
      "epoch: 149, batch_num: 0 loss: [[0.0137678]]\n",
      "epoch: 150, batch_num: 0 loss: [[0.01367463]]\n",
      "epoch: 151, batch_num: 0 loss: [[0.01358271]]\n",
      "epoch: 152, batch_num: 0 loss: [[0.01349201]]\n",
      "epoch: 153, batch_num: 0 loss: [[0.01340251]]\n",
      "epoch: 154, batch_num: 0 loss: [[0.01331418]]\n",
      "epoch: 155, batch_num: 0 loss: [[0.013227]]\n",
      "epoch: 156, batch_num: 0 loss: [[0.01314095]]\n",
      "epoch: 157, batch_num: 0 loss: [[0.01305601]]\n",
      "epoch: 158, batch_num: 0 loss: [[0.01297215]]\n",
      "epoch: 159, batch_num: 0 loss: [[0.01288936]]\n",
      "epoch: 160, batch_num: 0 loss: [[0.01280762]]\n",
      "epoch: 161, batch_num: 0 loss: [[0.0127269]]\n",
      "epoch: 162, batch_num: 0 loss: [[0.01264718]]\n",
      "epoch: 163, batch_num: 0 loss: [[0.01256845]]\n",
      "epoch: 164, batch_num: 0 loss: [[0.0124907]]\n",
      "epoch: 165, batch_num: 0 loss: [[0.01241389]]\n",
      "epoch: 166, batch_num: 0 loss: [[0.01233802]]\n",
      "epoch: 167, batch_num: 0 loss: [[0.01226307]]\n",
      "epoch: 168, batch_num: 0 loss: [[0.01218901]]\n",
      "epoch: 169, batch_num: 0 loss: [[0.01211584]]\n",
      "epoch: 170, batch_num: 0 loss: [[0.01204355]]\n",
      "epoch: 171, batch_num: 0 loss: [[0.0119721]]\n",
      "epoch: 172, batch_num: 0 loss: [[0.0119015]]\n",
      "epoch: 173, batch_num: 0 loss: [[0.01183171]]\n",
      "epoch: 174, batch_num: 0 loss: [[0.01176274]]\n",
      "epoch: 175, batch_num: 0 loss: [[0.01169457]]\n",
      "epoch: 176, batch_num: 0 loss: [[0.01162717]]\n",
      "epoch: 177, batch_num: 0 loss: [[0.01156055]]\n",
      "epoch: 178, batch_num: 0 loss: [[0.01149468]]\n",
      "epoch: 179, batch_num: 0 loss: [[0.01142955]]\n",
      "epoch: 180, batch_num: 0 loss: [[0.01136516]]\n",
      "epoch: 181, batch_num: 0 loss: [[0.01130148]]\n",
      "epoch: 182, batch_num: 0 loss: [[0.01123851]]\n",
      "epoch: 183, batch_num: 0 loss: [[0.01117624]]\n",
      "epoch: 184, batch_num: 0 loss: [[0.01111465]]\n",
      "epoch: 185, batch_num: 0 loss: [[0.01105373]]\n",
      "epoch: 186, batch_num: 0 loss: [[0.01099347]]\n",
      "epoch: 187, batch_num: 0 loss: [[0.01093386]]\n",
      "epoch: 188, batch_num: 0 loss: [[0.0108749]]\n",
      "epoch: 189, batch_num: 0 loss: [[0.01081656]]\n",
      "epoch: 190, batch_num: 0 loss: [[0.01075885]]\n",
      "epoch: 191, batch_num: 0 loss: [[0.01070174]]\n",
      "epoch: 192, batch_num: 0 loss: [[0.01064523]]\n",
      "epoch: 193, batch_num: 0 loss: [[0.01058932]]\n",
      "epoch: 194, batch_num: 0 loss: [[0.01053399]]\n",
      "epoch: 195, batch_num: 0 loss: [[0.01047923]]\n",
      "epoch: 196, batch_num: 0 loss: [[0.01042503]]\n",
      "epoch: 197, batch_num: 0 loss: [[0.01037139]]\n",
      "epoch: 198, batch_num: 0 loss: [[0.0103183]]\n",
      "epoch: 199, batch_num: 0 loss: [[0.01026574]]\n",
      "epoch: 200, batch_num: 0 loss: [[0.01021372]]\n",
      "epoch: 201, batch_num: 0 loss: [[0.01016222]]\n",
      "epoch: 202, batch_num: 0 loss: [[0.01011123]]\n",
      "epoch: 203, batch_num: 0 loss: [[0.01006076]]\n",
      "epoch: 204, batch_num: 0 loss: [[0.01001078]]\n",
      "epoch: 205, batch_num: 0 loss: [[0.00996129]]\n",
      "epoch: 206, batch_num: 0 loss: [[0.00991229]]\n",
      "epoch: 207, batch_num: 0 loss: [[0.00986376]]\n",
      "epoch: 208, batch_num: 0 loss: [[0.00981571]]\n",
      "epoch: 209, batch_num: 0 loss: [[0.00976812]]\n",
      "epoch: 210, batch_num: 0 loss: [[0.00972099]]\n",
      "epoch: 211, batch_num: 0 loss: [[0.00967431]]\n",
      "epoch: 212, batch_num: 0 loss: [[0.00962807]]\n",
      "epoch: 213, batch_num: 0 loss: [[0.00958228]]\n",
      "epoch: 214, batch_num: 0 loss: [[0.00953691]]\n",
      "epoch: 215, batch_num: 0 loss: [[0.00949197]]\n",
      "epoch: 216, batch_num: 0 loss: [[0.00944745]]\n",
      "epoch: 217, batch_num: 0 loss: [[0.00940335]]\n",
      "epoch: 218, batch_num: 0 loss: [[0.00935965]]\n",
      "epoch: 219, batch_num: 0 loss: [[0.00931636]]\n",
      "epoch: 220, batch_num: 0 loss: [[0.00927346]]\n",
      "epoch: 221, batch_num: 0 loss: [[0.00923096]]\n",
      "epoch: 222, batch_num: 0 loss: [[0.00918884]]\n",
      "epoch: 223, batch_num: 0 loss: [[0.0091471]]\n",
      "epoch: 224, batch_num: 0 loss: [[0.00910574]]\n",
      "epoch: 225, batch_num: 0 loss: [[0.00906475]]\n",
      "epoch: 226, batch_num: 0 loss: [[0.00902413]]\n",
      "epoch: 227, batch_num: 0 loss: [[0.00898387]]\n",
      "epoch: 228, batch_num: 0 loss: [[0.00894396]]\n",
      "epoch: 229, batch_num: 0 loss: [[0.00890441]]\n",
      "epoch: 230, batch_num: 0 loss: [[0.0088652]]\n",
      "epoch: 231, batch_num: 0 loss: [[0.00882633]]\n",
      "epoch: 232, batch_num: 0 loss: [[0.00878781]]\n",
      "epoch: 233, batch_num: 0 loss: [[0.00874962]]\n",
      "epoch: 234, batch_num: 0 loss: [[0.00871175]]\n",
      "epoch: 235, batch_num: 0 loss: [[0.00867422]]\n",
      "epoch: 236, batch_num: 0 loss: [[0.008637]]\n",
      "epoch: 237, batch_num: 0 loss: [[0.0086001]]\n",
      "epoch: 238, batch_num: 0 loss: [[0.00856351]]\n",
      "epoch: 239, batch_num: 0 loss: [[0.00852723]]\n",
      "epoch: 240, batch_num: 0 loss: [[0.00849126]]\n",
      "epoch: 241, batch_num: 0 loss: [[0.00845559]]\n",
      "epoch: 242, batch_num: 0 loss: [[0.00842022]]\n",
      "epoch: 243, batch_num: 0 loss: [[0.00838514]]\n",
      "epoch: 244, batch_num: 0 loss: [[0.00835035]]\n",
      "epoch: 245, batch_num: 0 loss: [[0.00831584]]\n",
      "epoch: 246, batch_num: 0 loss: [[0.00828162]]\n",
      "epoch: 247, batch_num: 0 loss: [[0.00824768]]\n",
      "epoch: 248, batch_num: 0 loss: [[0.00821402]]\n",
      "epoch: 249, batch_num: 0 loss: [[0.00818063]]\n",
      "epoch: 250, batch_num: 0 loss: [[0.00814751]]\n",
      "epoch: 251, batch_num: 0 loss: [[0.00811465]]\n",
      "epoch: 252, batch_num: 0 loss: [[0.00808206]]\n",
      "epoch: 253, batch_num: 0 loss: [[0.00804972]]\n",
      "epoch: 254, batch_num: 0 loss: [[0.00801765]]\n",
      "epoch: 255, batch_num: 0 loss: [[0.00798583]]\n",
      "epoch: 256, batch_num: 0 loss: [[0.00795426]]\n",
      "epoch: 257, batch_num: 0 loss: [[0.00792293]]\n",
      "epoch: 258, batch_num: 0 loss: [[0.00789186]]\n",
      "epoch: 259, batch_num: 0 loss: [[0.00786102]]\n",
      "epoch: 260, batch_num: 0 loss: [[0.00783042]]\n",
      "epoch: 261, batch_num: 0 loss: [[0.00780006]]\n",
      "epoch: 262, batch_num: 0 loss: [[0.00776994]]\n",
      "epoch: 263, batch_num: 0 loss: [[0.00774004]]\n",
      "epoch: 264, batch_num: 0 loss: [[0.00771037]]\n",
      "epoch: 265, batch_num: 0 loss: [[0.00768093]]\n",
      "epoch: 266, batch_num: 0 loss: [[0.00765172]]\n",
      "epoch: 267, batch_num: 0 loss: [[0.00762272]]\n",
      "epoch: 268, batch_num: 0 loss: [[0.00759394]]\n",
      "epoch: 269, batch_num: 0 loss: [[0.00756538]]\n",
      "epoch: 270, batch_num: 0 loss: [[0.00753703]]\n",
      "epoch: 271, batch_num: 0 loss: [[0.00750889]]\n",
      "epoch: 272, batch_num: 0 loss: [[0.00748096]]\n",
      "epoch: 273, batch_num: 0 loss: [[0.00745324]]\n",
      "epoch: 274, batch_num: 0 loss: [[0.00742572]]\n",
      "epoch: 275, batch_num: 0 loss: [[0.00739841]]\n",
      "epoch: 276, batch_num: 0 loss: [[0.00737129]]\n",
      "epoch: 277, batch_num: 0 loss: [[0.00734437]]\n",
      "epoch: 278, batch_num: 0 loss: [[0.00731765]]\n",
      "epoch: 279, batch_num: 0 loss: [[0.00729111]]\n",
      "epoch: 280, batch_num: 0 loss: [[0.00726478]]\n",
      "epoch: 281, batch_num: 0 loss: [[0.00723862]]\n",
      "epoch: 282, batch_num: 0 loss: [[0.00721266]]\n",
      "epoch: 283, batch_num: 0 loss: [[0.00718688]]\n",
      "epoch: 284, batch_num: 0 loss: [[0.00716129]]\n",
      "epoch: 285, batch_num: 0 loss: [[0.00713587]]\n",
      "epoch: 286, batch_num: 0 loss: [[0.00711064]]\n",
      "epoch: 287, batch_num: 0 loss: [[0.00708558]]\n",
      "epoch: 288, batch_num: 0 loss: [[0.0070607]]\n",
      "epoch: 289, batch_num: 0 loss: [[0.00703599]]\n",
      "epoch: 290, batch_num: 0 loss: [[0.00701145]]\n",
      "epoch: 291, batch_num: 0 loss: [[0.00698709]]\n",
      "epoch: 292, batch_num: 0 loss: [[0.00696289]]\n",
      "epoch: 293, batch_num: 0 loss: [[0.00693886]]\n",
      "epoch: 294, batch_num: 0 loss: [[0.00691499]]\n",
      "epoch: 295, batch_num: 0 loss: [[0.00689129]]\n",
      "epoch: 296, batch_num: 0 loss: [[0.00686775]]\n",
      "epoch: 297, batch_num: 0 loss: [[0.00684437]]\n",
      "epoch: 298, batch_num: 0 loss: [[0.00682114]]\n",
      "epoch: 299, batch_num: 0 loss: [[0.00679807]]\n",
      "epoch: 300, batch_num: 0 loss: [[0.00677516]]\n",
      "epoch: 301, batch_num: 0 loss: [[0.0067524]]\n",
      "epoch: 302, batch_num: 0 loss: [[0.0067298]]\n",
      "epoch: 303, batch_num: 0 loss: [[0.00670734]]\n",
      "epoch: 304, batch_num: 0 loss: [[0.00668504]]\n",
      "epoch: 305, batch_num: 0 loss: [[0.00666288]]\n",
      "epoch: 306, batch_num: 0 loss: [[0.00664086]]\n",
      "epoch: 307, batch_num: 0 loss: [[0.00661899]]\n",
      "epoch: 308, batch_num: 0 loss: [[0.00659727]]\n",
      "epoch: 309, batch_num: 0 loss: [[0.00657568]]\n",
      "epoch: 310, batch_num: 0 loss: [[0.00655424]]\n",
      "epoch: 311, batch_num: 0 loss: [[0.00653294]]\n",
      "epoch: 312, batch_num: 0 loss: [[0.00651177]]\n",
      "epoch: 313, batch_num: 0 loss: [[0.00649074]]\n",
      "epoch: 314, batch_num: 0 loss: [[0.00646985]]\n",
      "epoch: 315, batch_num: 0 loss: [[0.00644908]]\n",
      "epoch: 316, batch_num: 0 loss: [[0.00642846]]\n",
      "epoch: 317, batch_num: 0 loss: [[0.00640796]]\n",
      "epoch: 318, batch_num: 0 loss: [[0.00638759]]\n",
      "epoch: 319, batch_num: 0 loss: [[0.00636735]]\n",
      "epoch: 320, batch_num: 0 loss: [[0.00634724]]\n",
      "epoch: 321, batch_num: 0 loss: [[0.00632726]]\n",
      "epoch: 322, batch_num: 0 loss: [[0.0063074]]\n",
      "epoch: 323, batch_num: 0 loss: [[0.00628766]]\n",
      "epoch: 324, batch_num: 0 loss: [[0.00626805]]\n",
      "epoch: 325, batch_num: 0 loss: [[0.00624856]]\n",
      "epoch: 326, batch_num: 0 loss: [[0.00622918]]\n",
      "epoch: 327, batch_num: 0 loss: [[0.00620993]]\n",
      "epoch: 328, batch_num: 0 loss: [[0.0061908]]\n",
      "epoch: 329, batch_num: 0 loss: [[0.00617179]]\n",
      "epoch: 330, batch_num: 0 loss: [[0.00615289]]\n",
      "epoch: 331, batch_num: 0 loss: [[0.0061341]]\n",
      "epoch: 332, batch_num: 0 loss: [[0.00611543]]\n",
      "epoch: 333, batch_num: 0 loss: [[0.00609687]]\n",
      "epoch: 334, batch_num: 0 loss: [[0.00607843]]\n",
      "epoch: 335, batch_num: 0 loss: [[0.00606009]]\n",
      "epoch: 336, batch_num: 0 loss: [[0.00604187]]\n",
      "epoch: 337, batch_num: 0 loss: [[0.00602376]]\n",
      "epoch: 338, batch_num: 0 loss: [[0.00600575]]\n",
      "epoch: 339, batch_num: 0 loss: [[0.00598785]]\n",
      "epoch: 340, batch_num: 0 loss: [[0.00597005]]\n",
      "epoch: 341, batch_num: 0 loss: [[0.00595237]]\n",
      "epoch: 342, batch_num: 0 loss: [[0.00593478]]\n",
      "epoch: 343, batch_num: 0 loss: [[0.0059173]]\n",
      "epoch: 344, batch_num: 0 loss: [[0.00589992]]\n",
      "epoch: 345, batch_num: 0 loss: [[0.00588265]]\n",
      "epoch: 346, batch_num: 0 loss: [[0.00586547]]\n",
      "epoch: 347, batch_num: 0 loss: [[0.00584839]]\n",
      "epoch: 348, batch_num: 0 loss: [[0.00583142]]\n",
      "epoch: 349, batch_num: 0 loss: [[0.00581454]]\n",
      "epoch: 350, batch_num: 0 loss: [[0.00579775]]\n",
      "epoch: 351, batch_num: 0 loss: [[0.00578107]]\n",
      "epoch: 352, batch_num: 0 loss: [[0.00576448]]\n",
      "epoch: 353, batch_num: 0 loss: [[0.00574798]]\n",
      "epoch: 354, batch_num: 0 loss: [[0.00573158]]\n",
      "epoch: 355, batch_num: 0 loss: [[0.00571527]]\n",
      "epoch: 356, batch_num: 0 loss: [[0.00569906]]\n",
      "epoch: 357, batch_num: 0 loss: [[0.00568293]]\n",
      "epoch: 358, batch_num: 0 loss: [[0.0056669]]\n",
      "epoch: 359, batch_num: 0 loss: [[0.00565095]]\n",
      "epoch: 360, batch_num: 0 loss: [[0.0056351]]\n",
      "epoch: 361, batch_num: 0 loss: [[0.00561933]]\n",
      "epoch: 362, batch_num: 0 loss: [[0.00560365]]\n",
      "epoch: 363, batch_num: 0 loss: [[0.00558806]]\n",
      "epoch: 364, batch_num: 0 loss: [[0.00557256]]\n",
      "epoch: 365, batch_num: 0 loss: [[0.00555714]]\n",
      "epoch: 366, batch_num: 0 loss: [[0.00554181]]\n",
      "epoch: 367, batch_num: 0 loss: [[0.00552656]]\n",
      "epoch: 368, batch_num: 0 loss: [[0.00551139]]\n",
      "epoch: 369, batch_num: 0 loss: [[0.00549631]]\n",
      "epoch: 370, batch_num: 0 loss: [[0.0054813]]\n",
      "epoch: 371, batch_num: 0 loss: [[0.00546638]]\n",
      "epoch: 372, batch_num: 0 loss: [[0.00545154]]\n",
      "epoch: 373, batch_num: 0 loss: [[0.00543679]]\n",
      "epoch: 374, batch_num: 0 loss: [[0.00542211]]\n",
      "epoch: 375, batch_num: 0 loss: [[0.00540751]]\n",
      "epoch: 376, batch_num: 0 loss: [[0.00539298]]\n",
      "epoch: 377, batch_num: 0 loss: [[0.00537854]]\n",
      "epoch: 378, batch_num: 0 loss: [[0.00536417]]\n",
      "epoch: 379, batch_num: 0 loss: [[0.00534988]]\n",
      "epoch: 380, batch_num: 0 loss: [[0.00533566]]\n",
      "epoch: 381, batch_num: 0 loss: [[0.00532152]]\n",
      "epoch: 382, batch_num: 0 loss: [[0.00530746]]\n",
      "epoch: 383, batch_num: 0 loss: [[0.00529347]]\n",
      "epoch: 384, batch_num: 0 loss: [[0.00527955]]\n",
      "epoch: 385, batch_num: 0 loss: [[0.0052657]]\n",
      "epoch: 386, batch_num: 0 loss: [[0.00525193]]\n",
      "epoch: 387, batch_num: 0 loss: [[0.00523823]]\n",
      "epoch: 388, batch_num: 0 loss: [[0.0052246]]\n",
      "epoch: 389, batch_num: 0 loss: [[0.00521104]]\n",
      "epoch: 390, batch_num: 0 loss: [[0.00519755]]\n",
      "epoch: 391, batch_num: 0 loss: [[0.00518413]]\n",
      "epoch: 392, batch_num: 0 loss: [[0.00517078]]\n",
      "epoch: 393, batch_num: 0 loss: [[0.0051575]]\n",
      "epoch: 394, batch_num: 0 loss: [[0.00514428]]\n",
      "epoch: 395, batch_num: 0 loss: [[0.00513113]]\n",
      "epoch: 396, batch_num: 0 loss: [[0.00511805]]\n",
      "epoch: 397, batch_num: 0 loss: [[0.00510504]]\n",
      "epoch: 398, batch_num: 0 loss: [[0.00509209]]\n",
      "epoch: 399, batch_num: 0 loss: [[0.00507921]]\n",
      "epoch: 400, batch_num: 0 loss: [[0.00506639]]\n",
      "epoch: 401, batch_num: 0 loss: [[0.00505364]]\n",
      "epoch: 402, batch_num: 0 loss: [[0.00504095]]\n",
      "epoch: 403, batch_num: 0 loss: [[0.00502832]]\n",
      "epoch: 404, batch_num: 0 loss: [[0.00501576]]\n",
      "epoch: 405, batch_num: 0 loss: [[0.00500326]]\n",
      "epoch: 406, batch_num: 0 loss: [[0.00499082]]\n",
      "epoch: 407, batch_num: 0 loss: [[0.00497845]]\n",
      "epoch: 408, batch_num: 0 loss: [[0.00496613]]\n",
      "epoch: 409, batch_num: 0 loss: [[0.00495387]]\n",
      "epoch: 410, batch_num: 0 loss: [[0.00494168]]\n",
      "epoch: 411, batch_num: 0 loss: [[0.00492954]]\n",
      "epoch: 412, batch_num: 0 loss: [[0.00491747]]\n",
      "epoch: 413, batch_num: 0 loss: [[0.00490545]]\n",
      "epoch: 414, batch_num: 0 loss: [[0.00489349]]\n",
      "epoch: 415, batch_num: 0 loss: [[0.00488159]]\n",
      "epoch: 416, batch_num: 0 loss: [[0.00486975]]\n",
      "epoch: 417, batch_num: 0 loss: [[0.00485797]]\n",
      "epoch: 418, batch_num: 0 loss: [[0.00484624]]\n",
      "epoch: 419, batch_num: 0 loss: [[0.00483456]]\n",
      "epoch: 420, batch_num: 0 loss: [[0.00482295]]\n",
      "epoch: 421, batch_num: 0 loss: [[0.00481139]]\n",
      "epoch: 422, batch_num: 0 loss: [[0.00479988]]\n",
      "epoch: 423, batch_num: 0 loss: [[0.00478843]]\n",
      "epoch: 424, batch_num: 0 loss: [[0.00477704]]\n",
      "epoch: 425, batch_num: 0 loss: [[0.00476569]]\n",
      "epoch: 426, batch_num: 0 loss: [[0.0047544]]\n",
      "epoch: 427, batch_num: 0 loss: [[0.00474317]]\n",
      "epoch: 428, batch_num: 0 loss: [[0.00473199]]\n",
      "epoch: 429, batch_num: 0 loss: [[0.00472086]]\n",
      "epoch: 430, batch_num: 0 loss: [[0.00470978]]\n",
      "epoch: 431, batch_num: 0 loss: [[0.00469875]]\n",
      "epoch: 432, batch_num: 0 loss: [[0.00468778]]\n",
      "epoch: 433, batch_num: 0 loss: [[0.00467685]]\n",
      "epoch: 434, batch_num: 0 loss: [[0.00466598]]\n",
      "epoch: 435, batch_num: 0 loss: [[0.00465516]]\n",
      "epoch: 436, batch_num: 0 loss: [[0.00464439]]\n",
      "epoch: 437, batch_num: 0 loss: [[0.00463366]]\n",
      "epoch: 438, batch_num: 0 loss: [[0.00462299]]\n",
      "epoch: 439, batch_num: 0 loss: [[0.00461237]]\n",
      "epoch: 440, batch_num: 0 loss: [[0.00460179]]\n",
      "epoch: 441, batch_num: 0 loss: [[0.00459126]]\n",
      "epoch: 442, batch_num: 0 loss: [[0.00458078]]\n",
      "epoch: 443, batch_num: 0 loss: [[0.00457035]]\n",
      "epoch: 444, batch_num: 0 loss: [[0.00455997]]\n",
      "epoch: 445, batch_num: 0 loss: [[0.00454963]]\n",
      "epoch: 446, batch_num: 0 loss: [[0.00453934]]\n",
      "epoch: 447, batch_num: 0 loss: [[0.00452909]]\n",
      "epoch: 448, batch_num: 0 loss: [[0.00451889]]\n",
      "epoch: 449, batch_num: 0 loss: [[0.00450874]]\n",
      "epoch: 450, batch_num: 0 loss: [[0.00449863]]\n",
      "epoch: 451, batch_num: 0 loss: [[0.00448857]]\n",
      "epoch: 452, batch_num: 0 loss: [[0.00447855]]\n",
      "epoch: 453, batch_num: 0 loss: [[0.00446858]]\n",
      "epoch: 454, batch_num: 0 loss: [[0.00445865]]\n",
      "epoch: 455, batch_num: 0 loss: [[0.00444877]]\n",
      "epoch: 456, batch_num: 0 loss: [[0.00443893]]\n",
      "epoch: 457, batch_num: 0 loss: [[0.00442913]]\n",
      "epoch: 458, batch_num: 0 loss: [[0.00441938]]\n",
      "epoch: 459, batch_num: 0 loss: [[0.00440966]]\n",
      "epoch: 460, batch_num: 0 loss: [[0.00439999]]\n",
      "epoch: 461, batch_num: 0 loss: [[0.00439037]]\n",
      "epoch: 462, batch_num: 0 loss: [[0.00438078]]\n",
      "epoch: 463, batch_num: 0 loss: [[0.00437124]]\n",
      "epoch: 464, batch_num: 0 loss: [[0.00436174]]\n",
      "epoch: 465, batch_num: 0 loss: [[0.00435228]]\n",
      "epoch: 466, batch_num: 0 loss: [[0.00434286]]\n",
      "epoch: 467, batch_num: 0 loss: [[0.00433348]]\n",
      "epoch: 468, batch_num: 0 loss: [[0.00432414]]\n",
      "epoch: 469, batch_num: 0 loss: [[0.00431484]]\n",
      "epoch: 470, batch_num: 0 loss: [[0.00430558]]\n",
      "epoch: 471, batch_num: 0 loss: [[0.00429636]]\n",
      "epoch: 472, batch_num: 0 loss: [[0.00428718]]\n",
      "epoch: 473, batch_num: 0 loss: [[0.00427804]]\n",
      "epoch: 474, batch_num: 0 loss: [[0.00426894]]\n",
      "epoch: 475, batch_num: 0 loss: [[0.00425988]]\n",
      "epoch: 476, batch_num: 0 loss: [[0.00425085]]\n",
      "epoch: 477, batch_num: 0 loss: [[0.00424186]]\n",
      "epoch: 478, batch_num: 0 loss: [[0.00423291]]\n",
      "epoch: 479, batch_num: 0 loss: [[0.004224]]\n",
      "epoch: 480, batch_num: 0 loss: [[0.00421513]]\n",
      "epoch: 481, batch_num: 0 loss: [[0.00420629]]\n",
      "epoch: 482, batch_num: 0 loss: [[0.00419749]]\n",
      "epoch: 483, batch_num: 0 loss: [[0.00418873]]\n",
      "epoch: 484, batch_num: 0 loss: [[0.00418]]\n",
      "epoch: 485, batch_num: 0 loss: [[0.00417131]]\n",
      "epoch: 486, batch_num: 0 loss: [[0.00416266]]\n",
      "epoch: 487, batch_num: 0 loss: [[0.00415404]]\n",
      "epoch: 488, batch_num: 0 loss: [[0.00414545]]\n",
      "epoch: 489, batch_num: 0 loss: [[0.0041369]]\n",
      "epoch: 490, batch_num: 0 loss: [[0.00412839]]\n",
      "epoch: 491, batch_num: 0 loss: [[0.00411991]]\n",
      "epoch: 492, batch_num: 0 loss: [[0.00411147]]\n",
      "epoch: 493, batch_num: 0 loss: [[0.00410306]]\n",
      "epoch: 494, batch_num: 0 loss: [[0.00409469]]\n",
      "epoch: 495, batch_num: 0 loss: [[0.00408635]]\n",
      "epoch: 496, batch_num: 0 loss: [[0.00407804]]\n",
      "epoch: 497, batch_num: 0 loss: [[0.00406977]]\n",
      "epoch: 498, batch_num: 0 loss: [[0.00406153]]\n",
      "epoch: 499, batch_num: 0 loss: [[0.00405332]]\n",
      "epoch: 500, batch_num: 0 loss: [[0.00404515]]\n",
      "epoch: 501, batch_num: 0 loss: [[0.00403701]]\n",
      "epoch: 502, batch_num: 0 loss: [[0.0040289]]\n",
      "epoch: 503, batch_num: 0 loss: [[0.00402082]]\n",
      "epoch: 504, batch_num: 0 loss: [[0.00401278]]\n",
      "epoch: 505, batch_num: 0 loss: [[0.00400477]]\n",
      "epoch: 506, batch_num: 0 loss: [[0.00399679]]\n",
      "epoch: 507, batch_num: 0 loss: [[0.00398884]]\n",
      "epoch: 508, batch_num: 0 loss: [[0.00398093]]\n",
      "epoch: 509, batch_num: 0 loss: [[0.00397304]]\n",
      "epoch: 510, batch_num: 0 loss: [[0.00396519]]\n",
      "epoch: 511, batch_num: 0 loss: [[0.00395737]]\n",
      "epoch: 512, batch_num: 0 loss: [[0.00394958]]\n",
      "epoch: 513, batch_num: 0 loss: [[0.00394181]]\n",
      "epoch: 514, batch_num: 0 loss: [[0.00393408]]\n",
      "epoch: 515, batch_num: 0 loss: [[0.00392638]]\n",
      "epoch: 516, batch_num: 0 loss: [[0.00391871]]\n",
      "epoch: 517, batch_num: 0 loss: [[0.00391107]]\n",
      "epoch: 518, batch_num: 0 loss: [[0.00390346]]\n",
      "epoch: 519, batch_num: 0 loss: [[0.00389588]]\n",
      "epoch: 520, batch_num: 0 loss: [[0.00388833]]\n",
      "epoch: 521, batch_num: 0 loss: [[0.0038808]]\n",
      "epoch: 522, batch_num: 0 loss: [[0.00387331]]\n",
      "epoch: 523, batch_num: 0 loss: [[0.00386584]]\n",
      "epoch: 524, batch_num: 0 loss: [[0.00385841]]\n",
      "epoch: 525, batch_num: 0 loss: [[0.003851]]\n",
      "epoch: 526, batch_num: 0 loss: [[0.00384362]]\n",
      "epoch: 527, batch_num: 0 loss: [[0.00383627]]\n",
      "epoch: 528, batch_num: 0 loss: [[0.00382895]]\n",
      "epoch: 529, batch_num: 0 loss: [[0.00382165]]\n",
      "epoch: 530, batch_num: 0 loss: [[0.00381438]]\n",
      "epoch: 531, batch_num: 0 loss: [[0.00380714]]\n",
      "epoch: 532, batch_num: 0 loss: [[0.00379993]]\n",
      "epoch: 533, batch_num: 0 loss: [[0.00379274]]\n",
      "epoch: 534, batch_num: 0 loss: [[0.00378559]]\n",
      "epoch: 535, batch_num: 0 loss: [[0.00377845]]\n",
      "epoch: 536, batch_num: 0 loss: [[0.00377135]]\n",
      "epoch: 537, batch_num: 0 loss: [[0.00376427]]\n",
      "epoch: 538, batch_num: 0 loss: [[0.00375722]]\n",
      "epoch: 539, batch_num: 0 loss: [[0.00375019]]\n",
      "epoch: 540, batch_num: 0 loss: [[0.0037432]]\n",
      "epoch: 541, batch_num: 0 loss: [[0.00373622]]\n",
      "epoch: 542, batch_num: 0 loss: [[0.00372928]]\n",
      "epoch: 543, batch_num: 0 loss: [[0.00372235]]\n",
      "epoch: 544, batch_num: 0 loss: [[0.00371546]]\n",
      "epoch: 545, batch_num: 0 loss: [[0.00370859]]\n",
      "epoch: 546, batch_num: 0 loss: [[0.00370174]]\n",
      "epoch: 547, batch_num: 0 loss: [[0.00369492]]\n",
      "epoch: 548, batch_num: 0 loss: [[0.00368813]]\n",
      "epoch: 549, batch_num: 0 loss: [[0.00368136]]\n",
      "epoch: 550, batch_num: 0 loss: [[0.00367461]]\n",
      "epoch: 551, batch_num: 0 loss: [[0.00366789]]\n",
      "epoch: 552, batch_num: 0 loss: [[0.0036612]]\n",
      "epoch: 553, batch_num: 0 loss: [[0.00365452]]\n",
      "epoch: 554, batch_num: 0 loss: [[0.00364788]]\n",
      "epoch: 555, batch_num: 0 loss: [[0.00364125]]\n",
      "epoch: 556, batch_num: 0 loss: [[0.00363465]]\n",
      "epoch: 557, batch_num: 0 loss: [[0.00362808]]\n",
      "epoch: 558, batch_num: 0 loss: [[0.00362153]]\n",
      "epoch: 559, batch_num: 0 loss: [[0.003615]]\n",
      "epoch: 560, batch_num: 0 loss: [[0.00360849]]\n",
      "epoch: 561, batch_num: 0 loss: [[0.00360201]]\n",
      "epoch: 562, batch_num: 0 loss: [[0.00359556]]\n",
      "epoch: 563, batch_num: 0 loss: [[0.00358912]]\n",
      "epoch: 564, batch_num: 0 loss: [[0.00358271]]\n",
      "epoch: 565, batch_num: 0 loss: [[0.00357632]]\n",
      "epoch: 566, batch_num: 0 loss: [[0.00356995]]\n",
      "epoch: 567, batch_num: 0 loss: [[0.00356361]]\n",
      "epoch: 568, batch_num: 0 loss: [[0.00355729]]\n",
      "epoch: 569, batch_num: 0 loss: [[0.00355099]]\n",
      "epoch: 570, batch_num: 0 loss: [[0.00354471]]\n",
      "epoch: 571, batch_num: 0 loss: [[0.00353846]]\n",
      "epoch: 572, batch_num: 0 loss: [[0.00353222]]\n",
      "epoch: 573, batch_num: 0 loss: [[0.00352601]]\n",
      "epoch: 574, batch_num: 0 loss: [[0.00351982]]\n",
      "epoch: 575, batch_num: 0 loss: [[0.00351366]]\n",
      "epoch: 576, batch_num: 0 loss: [[0.00350751]]\n",
      "epoch: 577, batch_num: 0 loss: [[0.00350139]]\n",
      "epoch: 578, batch_num: 0 loss: [[0.00349528]]\n",
      "epoch: 579, batch_num: 0 loss: [[0.0034892]]\n",
      "epoch: 580, batch_num: 0 loss: [[0.00348314]]\n",
      "epoch: 581, batch_num: 0 loss: [[0.0034771]]\n",
      "epoch: 582, batch_num: 0 loss: [[0.00347108]]\n",
      "epoch: 583, batch_num: 0 loss: [[0.00346508]]\n",
      "epoch: 584, batch_num: 0 loss: [[0.00345911]]\n",
      "epoch: 585, batch_num: 0 loss: [[0.00345315]]\n",
      "epoch: 586, batch_num: 0 loss: [[0.00344721]]\n",
      "epoch: 587, batch_num: 0 loss: [[0.0034413]]\n",
      "epoch: 588, batch_num: 0 loss: [[0.0034354]]\n",
      "epoch: 589, batch_num: 0 loss: [[0.00342952]]\n",
      "epoch: 590, batch_num: 0 loss: [[0.00342367]]\n",
      "epoch: 591, batch_num: 0 loss: [[0.00341783]]\n",
      "epoch: 592, batch_num: 0 loss: [[0.00341202]]\n",
      "epoch: 593, batch_num: 0 loss: [[0.00340622]]\n",
      "epoch: 594, batch_num: 0 loss: [[0.00340044]]\n",
      "epoch: 595, batch_num: 0 loss: [[0.00339469]]\n",
      "epoch: 596, batch_num: 0 loss: [[0.00338895]]\n",
      "epoch: 597, batch_num: 0 loss: [[0.00338323]]\n",
      "epoch: 598, batch_num: 0 loss: [[0.00337753]]\n",
      "epoch: 599, batch_num: 0 loss: [[0.00337185]]\n",
      "epoch: 600, batch_num: 0 loss: [[0.00336619]]\n",
      "epoch: 601, batch_num: 0 loss: [[0.00336055]]\n",
      "epoch: 602, batch_num: 0 loss: [[0.00335493]]\n",
      "epoch: 603, batch_num: 0 loss: [[0.00334932]]\n",
      "epoch: 604, batch_num: 0 loss: [[0.00334374]]\n",
      "epoch: 605, batch_num: 0 loss: [[0.00333817]]\n",
      "epoch: 606, batch_num: 0 loss: [[0.00333262]]\n",
      "epoch: 607, batch_num: 0 loss: [[0.00332709]]\n",
      "epoch: 608, batch_num: 0 loss: [[0.00332158]]\n",
      "epoch: 609, batch_num: 0 loss: [[0.00331609]]\n",
      "epoch: 610, batch_num: 0 loss: [[0.00331061]]\n",
      "epoch: 611, batch_num: 0 loss: [[0.00330515]]\n",
      "epoch: 612, batch_num: 0 loss: [[0.00329971]]\n",
      "epoch: 613, batch_num: 0 loss: [[0.00329429]]\n",
      "epoch: 614, batch_num: 0 loss: [[0.00328889]]\n",
      "epoch: 615, batch_num: 0 loss: [[0.0032835]]\n",
      "epoch: 616, batch_num: 0 loss: [[0.00327813]]\n",
      "epoch: 617, batch_num: 0 loss: [[0.00327278]]\n",
      "epoch: 618, batch_num: 0 loss: [[0.00326745]]\n",
      "epoch: 619, batch_num: 0 loss: [[0.00326213]]\n",
      "epoch: 620, batch_num: 0 loss: [[0.00325683]]\n",
      "epoch: 621, batch_num: 0 loss: [[0.00325155]]\n",
      "epoch: 622, batch_num: 0 loss: [[0.00324629]]\n",
      "epoch: 623, batch_num: 0 loss: [[0.00324104]]\n",
      "epoch: 624, batch_num: 0 loss: [[0.00323581]]\n",
      "epoch: 625, batch_num: 0 loss: [[0.00323059]]\n",
      "epoch: 626, batch_num: 0 loss: [[0.0032254]]\n",
      "epoch: 627, batch_num: 0 loss: [[0.00322021]]\n",
      "epoch: 628, batch_num: 0 loss: [[0.00321505]]\n",
      "epoch: 629, batch_num: 0 loss: [[0.0032099]]\n",
      "epoch: 630, batch_num: 0 loss: [[0.00320477]]\n",
      "epoch: 631, batch_num: 0 loss: [[0.00319966]]\n",
      "epoch: 632, batch_num: 0 loss: [[0.00319456]]\n",
      "epoch: 633, batch_num: 0 loss: [[0.00318948]]\n",
      "epoch: 634, batch_num: 0 loss: [[0.00318441]]\n",
      "epoch: 635, batch_num: 0 loss: [[0.00317936]]\n",
      "epoch: 636, batch_num: 0 loss: [[0.00317433]]\n",
      "epoch: 637, batch_num: 0 loss: [[0.00316931]]\n",
      "epoch: 638, batch_num: 0 loss: [[0.00316431]]\n",
      "epoch: 639, batch_num: 0 loss: [[0.00315932]]\n",
      "epoch: 640, batch_num: 0 loss: [[0.00315435]]\n",
      "epoch: 641, batch_num: 0 loss: [[0.00314939]]\n",
      "epoch: 642, batch_num: 0 loss: [[0.00314445]]\n",
      "epoch: 643, batch_num: 0 loss: [[0.00313953]]\n",
      "epoch: 644, batch_num: 0 loss: [[0.00313462]]\n",
      "epoch: 645, batch_num: 0 loss: [[0.00312973]]\n",
      "epoch: 646, batch_num: 0 loss: [[0.00312485]]\n",
      "epoch: 647, batch_num: 0 loss: [[0.00311998]]\n",
      "epoch: 648, batch_num: 0 loss: [[0.00311514]]\n",
      "epoch: 649, batch_num: 0 loss: [[0.0031103]]\n",
      "epoch: 650, batch_num: 0 loss: [[0.00310548]]\n",
      "epoch: 651, batch_num: 0 loss: [[0.00310068]]\n",
      "epoch: 652, batch_num: 0 loss: [[0.00309589]]\n",
      "epoch: 653, batch_num: 0 loss: [[0.00309112]]\n",
      "epoch: 654, batch_num: 0 loss: [[0.00308636]]\n",
      "epoch: 655, batch_num: 0 loss: [[0.00308161]]\n",
      "epoch: 656, batch_num: 0 loss: [[0.00307688]]\n",
      "epoch: 657, batch_num: 0 loss: [[0.00307217]]\n",
      "epoch: 658, batch_num: 0 loss: [[0.00306747]]\n",
      "epoch: 659, batch_num: 0 loss: [[0.00306278]]\n",
      "epoch: 660, batch_num: 0 loss: [[0.00305811]]\n",
      "epoch: 661, batch_num: 0 loss: [[0.00305345]]\n",
      "epoch: 662, batch_num: 0 loss: [[0.00304881]]\n",
      "epoch: 663, batch_num: 0 loss: [[0.00304418]]\n",
      "epoch: 664, batch_num: 0 loss: [[0.00303956]]\n",
      "epoch: 665, batch_num: 0 loss: [[0.00303496]]\n",
      "epoch: 666, batch_num: 0 loss: [[0.00303037]]\n",
      "epoch: 667, batch_num: 0 loss: [[0.0030258]]\n",
      "epoch: 668, batch_num: 0 loss: [[0.00302124]]\n",
      "epoch: 669, batch_num: 0 loss: [[0.00301669]]\n",
      "epoch: 670, batch_num: 0 loss: [[0.00301216]]\n",
      "epoch: 671, batch_num: 0 loss: [[0.00300764]]\n",
      "epoch: 672, batch_num: 0 loss: [[0.00300313]]\n",
      "epoch: 673, batch_num: 0 loss: [[0.00299864]]\n",
      "epoch: 674, batch_num: 0 loss: [[0.00299416]]\n",
      "epoch: 675, batch_num: 0 loss: [[0.00298969]]\n",
      "epoch: 676, batch_num: 0 loss: [[0.00298524]]\n",
      "epoch: 677, batch_num: 0 loss: [[0.0029808]]\n",
      "epoch: 678, batch_num: 0 loss: [[0.00297638]]\n",
      "epoch: 679, batch_num: 0 loss: [[0.00297196]]\n",
      "epoch: 680, batch_num: 0 loss: [[0.00296756]]\n",
      "epoch: 681, batch_num: 0 loss: [[0.00296318]]\n",
      "epoch: 682, batch_num: 0 loss: [[0.0029588]]\n",
      "epoch: 683, batch_num: 0 loss: [[0.00295444]]\n",
      "epoch: 684, batch_num: 0 loss: [[0.00295009]]\n",
      "epoch: 685, batch_num: 0 loss: [[0.00294576]]\n",
      "epoch: 686, batch_num: 0 loss: [[0.00294143]]\n",
      "epoch: 687, batch_num: 0 loss: [[0.00293712]]\n",
      "epoch: 688, batch_num: 0 loss: [[0.00293283]]\n",
      "epoch: 689, batch_num: 0 loss: [[0.00292854]]\n",
      "epoch: 690, batch_num: 0 loss: [[0.00292427]]\n",
      "epoch: 691, batch_num: 0 loss: [[0.00292001]]\n",
      "epoch: 692, batch_num: 0 loss: [[0.00291576]]\n",
      "epoch: 693, batch_num: 0 loss: [[0.00291153]]\n",
      "epoch: 694, batch_num: 0 loss: [[0.0029073]]\n",
      "epoch: 695, batch_num: 0 loss: [[0.00290309]]\n",
      "epoch: 696, batch_num: 0 loss: [[0.00289889]]\n",
      "epoch: 697, batch_num: 0 loss: [[0.00289471]]\n",
      "epoch: 698, batch_num: 0 loss: [[0.00289053]]\n",
      "epoch: 699, batch_num: 0 loss: [[0.00288637]]\n",
      "epoch: 700, batch_num: 0 loss: [[0.00288222]]\n",
      "epoch: 701, batch_num: 0 loss: [[0.00287808]]\n",
      "epoch: 702, batch_num: 0 loss: [[0.00287395]]\n",
      "epoch: 703, batch_num: 0 loss: [[0.00286984]]\n",
      "epoch: 704, batch_num: 0 loss: [[0.00286573]]\n",
      "epoch: 705, batch_num: 0 loss: [[0.00286164]]\n",
      "epoch: 706, batch_num: 0 loss: [[0.00285756]]\n",
      "epoch: 707, batch_num: 0 loss: [[0.0028535]]\n",
      "epoch: 708, batch_num: 0 loss: [[0.00284944]]\n",
      "epoch: 709, batch_num: 0 loss: [[0.00284539]]\n",
      "epoch: 710, batch_num: 0 loss: [[0.00284136]]\n",
      "epoch: 711, batch_num: 0 loss: [[0.00283734]]\n",
      "epoch: 712, batch_num: 0 loss: [[0.00283333]]\n",
      "epoch: 713, batch_num: 0 loss: [[0.00282933]]\n",
      "epoch: 714, batch_num: 0 loss: [[0.00282534]]\n",
      "epoch: 715, batch_num: 0 loss: [[0.00282136]]\n",
      "epoch: 716, batch_num: 0 loss: [[0.00281739]]\n",
      "epoch: 717, batch_num: 0 loss: [[0.00281344]]\n",
      "epoch: 718, batch_num: 0 loss: [[0.0028095]]\n",
      "epoch: 719, batch_num: 0 loss: [[0.00280556]]\n",
      "epoch: 720, batch_num: 0 loss: [[0.00280164]]\n",
      "epoch: 721, batch_num: 0 loss: [[0.00279773]]\n",
      "epoch: 722, batch_num: 0 loss: [[0.00279383]]\n",
      "epoch: 723, batch_num: 0 loss: [[0.00278994]]\n",
      "epoch: 724, batch_num: 0 loss: [[0.00278606]]\n",
      "epoch: 725, batch_num: 0 loss: [[0.0027822]]\n",
      "epoch: 726, batch_num: 0 loss: [[0.00277834]]\n",
      "epoch: 727, batch_num: 0 loss: [[0.00277449]]\n",
      "epoch: 728, batch_num: 0 loss: [[0.00277066]]\n",
      "epoch: 729, batch_num: 0 loss: [[0.00276683]]\n",
      "epoch: 730, batch_num: 0 loss: [[0.00276302]]\n",
      "epoch: 731, batch_num: 0 loss: [[0.00275921]]\n",
      "epoch: 732, batch_num: 0 loss: [[0.00275542]]\n",
      "epoch: 733, batch_num: 0 loss: [[0.00275164]]\n",
      "epoch: 734, batch_num: 0 loss: [[0.00274786]]\n",
      "epoch: 735, batch_num: 0 loss: [[0.0027441]]\n",
      "epoch: 736, batch_num: 0 loss: [[0.00274035]]\n",
      "epoch: 737, batch_num: 0 loss: [[0.00273661]]\n",
      "epoch: 738, batch_num: 0 loss: [[0.00273288]]\n",
      "epoch: 739, batch_num: 0 loss: [[0.00272915]]\n",
      "epoch: 740, batch_num: 0 loss: [[0.00272544]]\n",
      "epoch: 741, batch_num: 0 loss: [[0.00272174]]\n",
      "epoch: 742, batch_num: 0 loss: [[0.00271805]]\n",
      "epoch: 743, batch_num: 0 loss: [[0.00271437]]\n",
      "epoch: 744, batch_num: 0 loss: [[0.0027107]]\n",
      "epoch: 745, batch_num: 0 loss: [[0.00270704]]\n",
      "epoch: 746, batch_num: 0 loss: [[0.00270338]]\n",
      "epoch: 747, batch_num: 0 loss: [[0.00269974]]\n",
      "epoch: 748, batch_num: 0 loss: [[0.00269611]]\n",
      "epoch: 749, batch_num: 0 loss: [[0.00269249]]\n",
      "epoch: 750, batch_num: 0 loss: [[0.00268887]]\n",
      "epoch: 751, batch_num: 0 loss: [[0.00268527]]\n",
      "epoch: 752, batch_num: 0 loss: [[0.00268168]]\n",
      "epoch: 753, batch_num: 0 loss: [[0.00267809]]\n",
      "epoch: 754, batch_num: 0 loss: [[0.00267452]]\n",
      "epoch: 755, batch_num: 0 loss: [[0.00267096]]\n",
      "epoch: 756, batch_num: 0 loss: [[0.0026674]]\n",
      "epoch: 757, batch_num: 0 loss: [[0.00266386]]\n",
      "epoch: 758, batch_num: 0 loss: [[0.00266032]]\n",
      "epoch: 759, batch_num: 0 loss: [[0.00265679]]\n",
      "epoch: 760, batch_num: 0 loss: [[0.00265327]]\n",
      "epoch: 761, batch_num: 0 loss: [[0.00264977]]\n",
      "epoch: 762, batch_num: 0 loss: [[0.00264627]]\n",
      "epoch: 763, batch_num: 0 loss: [[0.00264278]]\n",
      "epoch: 764, batch_num: 0 loss: [[0.0026393]]\n",
      "epoch: 765, batch_num: 0 loss: [[0.00263583]]\n",
      "epoch: 766, batch_num: 0 loss: [[0.00263236]]\n",
      "epoch: 767, batch_num: 0 loss: [[0.00262891]]\n",
      "epoch: 768, batch_num: 0 loss: [[0.00262547]]\n",
      "epoch: 769, batch_num: 0 loss: [[0.00262203]]\n",
      "epoch: 770, batch_num: 0 loss: [[0.0026186]]\n",
      "epoch: 771, batch_num: 0 loss: [[0.00261519]]\n",
      "epoch: 772, batch_num: 0 loss: [[0.00261178]]\n",
      "epoch: 773, batch_num: 0 loss: [[0.00260838]]\n",
      "epoch: 774, batch_num: 0 loss: [[0.00260499]]\n",
      "epoch: 775, batch_num: 0 loss: [[0.00260161]]\n",
      "epoch: 776, batch_num: 0 loss: [[0.00259823]]\n",
      "epoch: 777, batch_num: 0 loss: [[0.00259487]]\n",
      "epoch: 778, batch_num: 0 loss: [[0.00259151]]\n",
      "epoch: 779, batch_num: 0 loss: [[0.00258817]]\n",
      "epoch: 780, batch_num: 0 loss: [[0.00258483]]\n",
      "epoch: 781, batch_num: 0 loss: [[0.0025815]]\n",
      "epoch: 782, batch_num: 0 loss: [[0.00257818]]\n",
      "epoch: 783, batch_num: 0 loss: [[0.00257486]]\n",
      "epoch: 784, batch_num: 0 loss: [[0.00257156]]\n",
      "epoch: 785, batch_num: 0 loss: [[0.00256826]]\n",
      "epoch: 786, batch_num: 0 loss: [[0.00256498]]\n",
      "epoch: 787, batch_num: 0 loss: [[0.0025617]]\n",
      "epoch: 788, batch_num: 0 loss: [[0.00255843]]\n",
      "epoch: 789, batch_num: 0 loss: [[0.00255516]]\n",
      "epoch: 790, batch_num: 0 loss: [[0.00255191]]\n",
      "epoch: 791, batch_num: 0 loss: [[0.00254866]]\n",
      "epoch: 792, batch_num: 0 loss: [[0.00254543]]\n",
      "epoch: 793, batch_num: 0 loss: [[0.0025422]]\n",
      "epoch: 794, batch_num: 0 loss: [[0.00253898]]\n",
      "epoch: 795, batch_num: 0 loss: [[0.00253576]]\n",
      "epoch: 796, batch_num: 0 loss: [[0.00253256]]\n",
      "epoch: 797, batch_num: 0 loss: [[0.00252936]]\n",
      "epoch: 798, batch_num: 0 loss: [[0.00252617]]\n",
      "epoch: 799, batch_num: 0 loss: [[0.00252299]]\n",
      "epoch: 800, batch_num: 0 loss: [[0.00251982]]\n",
      "epoch: 801, batch_num: 0 loss: [[0.00251665]]\n",
      "epoch: 802, batch_num: 0 loss: [[0.0025135]]\n",
      "epoch: 803, batch_num: 0 loss: [[0.00251035]]\n",
      "epoch: 804, batch_num: 0 loss: [[0.00250721]]\n",
      "epoch: 805, batch_num: 0 loss: [[0.00250407]]\n",
      "epoch: 806, batch_num: 0 loss: [[0.00250095]]\n",
      "epoch: 807, batch_num: 0 loss: [[0.00249783]]\n",
      "epoch: 808, batch_num: 0 loss: [[0.00249472]]\n",
      "epoch: 809, batch_num: 0 loss: [[0.00249162]]\n",
      "epoch: 810, batch_num: 0 loss: [[0.00248852]]\n",
      "epoch: 811, batch_num: 0 loss: [[0.00248544]]\n",
      "epoch: 812, batch_num: 0 loss: [[0.00248236]]\n",
      "epoch: 813, batch_num: 0 loss: [[0.00247929]]\n",
      "epoch: 814, batch_num: 0 loss: [[0.00247622]]\n",
      "epoch: 815, batch_num: 0 loss: [[0.00247317]]\n",
      "epoch: 816, batch_num: 0 loss: [[0.00247012]]\n",
      "epoch: 817, batch_num: 0 loss: [[0.00246708]]\n",
      "epoch: 818, batch_num: 0 loss: [[0.00246404]]\n",
      "epoch: 819, batch_num: 0 loss: [[0.00246102]]\n",
      "epoch: 820, batch_num: 0 loss: [[0.002458]]\n",
      "epoch: 821, batch_num: 0 loss: [[0.00245499]]\n",
      "epoch: 822, batch_num: 0 loss: [[0.00245198]]\n",
      "epoch: 823, batch_num: 0 loss: [[0.00244898]]\n",
      "epoch: 824, batch_num: 0 loss: [[0.00244599]]\n",
      "epoch: 825, batch_num: 0 loss: [[0.00244301]]\n",
      "epoch: 826, batch_num: 0 loss: [[0.00244004]]\n",
      "epoch: 827, batch_num: 0 loss: [[0.00243707]]\n",
      "epoch: 828, batch_num: 0 loss: [[0.00243411]]\n",
      "epoch: 829, batch_num: 0 loss: [[0.00243116]]\n",
      "epoch: 830, batch_num: 0 loss: [[0.00242821]]\n",
      "epoch: 831, batch_num: 0 loss: [[0.00242527]]\n",
      "epoch: 832, batch_num: 0 loss: [[0.00242234]]\n",
      "epoch: 833, batch_num: 0 loss: [[0.00241941]]\n",
      "epoch: 834, batch_num: 0 loss: [[0.00241649]]\n",
      "epoch: 835, batch_num: 0 loss: [[0.00241358]]\n",
      "epoch: 836, batch_num: 0 loss: [[0.00241068]]\n",
      "epoch: 837, batch_num: 0 loss: [[0.00240778]]\n",
      "epoch: 838, batch_num: 0 loss: [[0.00240489]]\n",
      "epoch: 839, batch_num: 0 loss: [[0.00240201]]\n",
      "epoch: 840, batch_num: 0 loss: [[0.00239913]]\n",
      "epoch: 841, batch_num: 0 loss: [[0.00239626]]\n",
      "epoch: 842, batch_num: 0 loss: [[0.0023934]]\n",
      "epoch: 843, batch_num: 0 loss: [[0.00239055]]\n",
      "epoch: 844, batch_num: 0 loss: [[0.0023877]]\n",
      "epoch: 845, batch_num: 0 loss: [[0.00238486]]\n",
      "epoch: 846, batch_num: 0 loss: [[0.00238202]]\n",
      "epoch: 847, batch_num: 0 loss: [[0.00237919]]\n",
      "epoch: 848, batch_num: 0 loss: [[0.00237637]]\n",
      "epoch: 849, batch_num: 0 loss: [[0.00237355]]\n",
      "epoch: 850, batch_num: 0 loss: [[0.00237075]]\n",
      "epoch: 851, batch_num: 0 loss: [[0.00236794]]\n",
      "epoch: 852, batch_num: 0 loss: [[0.00236515]]\n",
      "epoch: 853, batch_num: 0 loss: [[0.00236236]]\n",
      "epoch: 854, batch_num: 0 loss: [[0.00235958]]\n",
      "epoch: 855, batch_num: 0 loss: [[0.0023568]]\n",
      "epoch: 856, batch_num: 0 loss: [[0.00235403]]\n",
      "epoch: 857, batch_num: 0 loss: [[0.00235127]]\n",
      "epoch: 858, batch_num: 0 loss: [[0.00234851]]\n",
      "epoch: 859, batch_num: 0 loss: [[0.00234576]]\n",
      "epoch: 860, batch_num: 0 loss: [[0.00234302]]\n",
      "epoch: 861, batch_num: 0 loss: [[0.00234028]]\n",
      "epoch: 862, batch_num: 0 loss: [[0.00233755]]\n",
      "epoch: 863, batch_num: 0 loss: [[0.00233483]]\n",
      "epoch: 864, batch_num: 0 loss: [[0.00233211]]\n",
      "epoch: 865, batch_num: 0 loss: [[0.0023294]]\n",
      "epoch: 866, batch_num: 0 loss: [[0.0023267]]\n",
      "epoch: 867, batch_num: 0 loss: [[0.002324]]\n",
      "epoch: 868, batch_num: 0 loss: [[0.0023213]]\n",
      "epoch: 869, batch_num: 0 loss: [[0.00231862]]\n",
      "epoch: 870, batch_num: 0 loss: [[0.00231594]]\n",
      "epoch: 871, batch_num: 0 loss: [[0.00231326]]\n",
      "epoch: 872, batch_num: 0 loss: [[0.0023106]]\n",
      "epoch: 873, batch_num: 0 loss: [[0.00230793]]\n",
      "epoch: 874, batch_num: 0 loss: [[0.00230528]]\n",
      "epoch: 875, batch_num: 0 loss: [[0.00230263]]\n",
      "epoch: 876, batch_num: 0 loss: [[0.00229999]]\n",
      "epoch: 877, batch_num: 0 loss: [[0.00229735]]\n",
      "epoch: 878, batch_num: 0 loss: [[0.00229472]]\n",
      "epoch: 879, batch_num: 0 loss: [[0.00229209]]\n",
      "epoch: 880, batch_num: 0 loss: [[0.00228947]]\n",
      "epoch: 881, batch_num: 0 loss: [[0.00228686]]\n",
      "epoch: 882, batch_num: 0 loss: [[0.00228425]]\n",
      "epoch: 883, batch_num: 0 loss: [[0.00228165]]\n",
      "epoch: 884, batch_num: 0 loss: [[0.00227905]]\n",
      "epoch: 885, batch_num: 0 loss: [[0.00227646]]\n",
      "epoch: 886, batch_num: 0 loss: [[0.00227388]]\n",
      "epoch: 887, batch_num: 0 loss: [[0.0022713]]\n",
      "epoch: 888, batch_num: 0 loss: [[0.00226873]]\n",
      "epoch: 889, batch_num: 0 loss: [[0.00226616]]\n",
      "epoch: 890, batch_num: 0 loss: [[0.0022636]]\n",
      "epoch: 891, batch_num: 0 loss: [[0.00226105]]\n",
      "epoch: 892, batch_num: 0 loss: [[0.0022585]]\n",
      "epoch: 893, batch_num: 0 loss: [[0.00225596]]\n",
      "epoch: 894, batch_num: 0 loss: [[0.00225342]]\n",
      "epoch: 895, batch_num: 0 loss: [[0.00225089]]\n",
      "epoch: 896, batch_num: 0 loss: [[0.00224836]]\n",
      "epoch: 897, batch_num: 0 loss: [[0.00224584]]\n",
      "epoch: 898, batch_num: 0 loss: [[0.00224333]]\n",
      "epoch: 899, batch_num: 0 loss: [[0.00224082]]\n",
      "epoch: 900, batch_num: 0 loss: [[0.00223831]]\n",
      "epoch: 901, batch_num: 0 loss: [[0.00223582]]\n",
      "epoch: 902, batch_num: 0 loss: [[0.00223332]]\n",
      "epoch: 903, batch_num: 0 loss: [[0.00223084]]\n",
      "epoch: 904, batch_num: 0 loss: [[0.00222835]]\n",
      "epoch: 905, batch_num: 0 loss: [[0.00222588]]\n",
      "epoch: 906, batch_num: 0 loss: [[0.00222341]]\n",
      "epoch: 907, batch_num: 0 loss: [[0.00222094]]\n",
      "epoch: 908, batch_num: 0 loss: [[0.00221848]]\n",
      "epoch: 909, batch_num: 0 loss: [[0.00221603]]\n",
      "epoch: 910, batch_num: 0 loss: [[0.00221358]]\n",
      "epoch: 911, batch_num: 0 loss: [[0.00221114]]\n",
      "epoch: 912, batch_num: 0 loss: [[0.0022087]]\n",
      "epoch: 913, batch_num: 0 loss: [[0.00220627]]\n",
      "epoch: 914, batch_num: 0 loss: [[0.00220384]]\n",
      "epoch: 915, batch_num: 0 loss: [[0.00220142]]\n",
      "epoch: 916, batch_num: 0 loss: [[0.002199]]\n",
      "epoch: 917, batch_num: 0 loss: [[0.00219659]]\n",
      "epoch: 918, batch_num: 0 loss: [[0.00219419]]\n",
      "epoch: 919, batch_num: 0 loss: [[0.00219178]]\n",
      "epoch: 920, batch_num: 0 loss: [[0.00218939]]\n",
      "epoch: 921, batch_num: 0 loss: [[0.002187]]\n",
      "epoch: 922, batch_num: 0 loss: [[0.00218461]]\n",
      "epoch: 923, batch_num: 0 loss: [[0.00218223]]\n",
      "epoch: 924, batch_num: 0 loss: [[0.00217986]]\n",
      "epoch: 925, batch_num: 0 loss: [[0.00217749]]\n",
      "epoch: 926, batch_num: 0 loss: [[0.00217513]]\n",
      "epoch: 927, batch_num: 0 loss: [[0.00217277]]\n",
      "epoch: 928, batch_num: 0 loss: [[0.00217041]]\n",
      "epoch: 929, batch_num: 0 loss: [[0.00216806]]\n",
      "epoch: 930, batch_num: 0 loss: [[0.00216572]]\n",
      "epoch: 931, batch_num: 0 loss: [[0.00216338]]\n",
      "epoch: 932, batch_num: 0 loss: [[0.00216105]]\n",
      "epoch: 933, batch_num: 0 loss: [[0.00215872]]\n",
      "epoch: 934, batch_num: 0 loss: [[0.00215639]]\n",
      "epoch: 935, batch_num: 0 loss: [[0.00215408]]\n",
      "epoch: 936, batch_num: 0 loss: [[0.00215176]]\n",
      "epoch: 937, batch_num: 0 loss: [[0.00214945]]\n",
      "epoch: 938, batch_num: 0 loss: [[0.00214715]]\n",
      "epoch: 939, batch_num: 0 loss: [[0.00214485]]\n",
      "epoch: 940, batch_num: 0 loss: [[0.00214256]]\n",
      "epoch: 941, batch_num: 0 loss: [[0.00214027]]\n",
      "epoch: 942, batch_num: 0 loss: [[0.00213798]]\n",
      "epoch: 943, batch_num: 0 loss: [[0.0021357]]\n",
      "epoch: 944, batch_num: 0 loss: [[0.00213343]]\n",
      "epoch: 945, batch_num: 0 loss: [[0.00213116]]\n",
      "epoch: 946, batch_num: 0 loss: [[0.00212889]]\n",
      "epoch: 947, batch_num: 0 loss: [[0.00212663]]\n",
      "epoch: 948, batch_num: 0 loss: [[0.00212438]]\n",
      "epoch: 949, batch_num: 0 loss: [[0.00212213]]\n",
      "epoch: 950, batch_num: 0 loss: [[0.00211988]]\n",
      "epoch: 951, batch_num: 0 loss: [[0.00211764]]\n",
      "epoch: 952, batch_num: 0 loss: [[0.00211541]]\n",
      "epoch: 953, batch_num: 0 loss: [[0.00211317]]\n",
      "epoch: 954, batch_num: 0 loss: [[0.00211095]]\n",
      "epoch: 955, batch_num: 0 loss: [[0.00210872]]\n",
      "epoch: 956, batch_num: 0 loss: [[0.00210651]]\n",
      "epoch: 957, batch_num: 0 loss: [[0.00210429]]\n",
      "epoch: 958, batch_num: 0 loss: [[0.00210209]]\n",
      "epoch: 959, batch_num: 0 loss: [[0.00209988]]\n",
      "epoch: 960, batch_num: 0 loss: [[0.00209768]]\n",
      "epoch: 961, batch_num: 0 loss: [[0.00209549]]\n",
      "epoch: 962, batch_num: 0 loss: [[0.0020933]]\n",
      "epoch: 963, batch_num: 0 loss: [[0.00209111]]\n",
      "epoch: 964, batch_num: 0 loss: [[0.00208893]]\n",
      "epoch: 965, batch_num: 0 loss: [[0.00208676]]\n",
      "epoch: 966, batch_num: 0 loss: [[0.00208459]]\n",
      "epoch: 967, batch_num: 0 loss: [[0.00208242]]\n",
      "epoch: 968, batch_num: 0 loss: [[0.00208026]]\n",
      "epoch: 969, batch_num: 0 loss: [[0.0020781]]\n",
      "epoch: 970, batch_num: 0 loss: [[0.00207594]]\n",
      "epoch: 971, batch_num: 0 loss: [[0.0020738]]\n",
      "epoch: 972, batch_num: 0 loss: [[0.00207165]]\n",
      "epoch: 973, batch_num: 0 loss: [[0.00206951]]\n",
      "epoch: 974, batch_num: 0 loss: [[0.00206737]]\n",
      "epoch: 975, batch_num: 0 loss: [[0.00206524]]\n",
      "epoch: 976, batch_num: 0 loss: [[0.00206312]]\n",
      "epoch: 977, batch_num: 0 loss: [[0.00206099]]\n",
      "epoch: 978, batch_num: 0 loss: [[0.00205887]]\n",
      "epoch: 979, batch_num: 0 loss: [[0.00205676]]\n",
      "epoch: 980, batch_num: 0 loss: [[0.00205465]]\n",
      "epoch: 981, batch_num: 0 loss: [[0.00205255]]\n",
      "epoch: 982, batch_num: 0 loss: [[0.00205044]]\n",
      "epoch: 983, batch_num: 0 loss: [[0.00204835]]\n",
      "epoch: 984, batch_num: 0 loss: [[0.00204626]]\n",
      "epoch: 985, batch_num: 0 loss: [[0.00204417]]\n",
      "epoch: 986, batch_num: 0 loss: [[0.00204208]]\n",
      "epoch: 987, batch_num: 0 loss: [[0.00204]]\n",
      "epoch: 988, batch_num: 0 loss: [[0.00203793]]\n",
      "epoch: 989, batch_num: 0 loss: [[0.00203586]]\n",
      "epoch: 990, batch_num: 0 loss: [[0.00203379]]\n",
      "epoch: 991, batch_num: 0 loss: [[0.00203173]]\n",
      "epoch: 992, batch_num: 0 loss: [[0.00202967]]\n",
      "epoch: 993, batch_num: 0 loss: [[0.00202761]]\n",
      "epoch: 994, batch_num: 0 loss: [[0.00202556]]\n",
      "epoch: 995, batch_num: 0 loss: [[0.00202352]]\n",
      "epoch: 996, batch_num: 0 loss: [[0.00202147]]\n",
      "epoch: 997, batch_num: 0 loss: [[0.00201944]]\n",
      "epoch: 998, batch_num: 0 loss: [[0.0020174]]\n",
      "epoch: 999, batch_num: 0 loss: [[0.00201537]]\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array([[1, 2], [2, 1]])\n",
    "train_labels = np.array([1, 0])\n",
    "train_labels = train_labels.reshape((train_data.shape[0], 1))\n",
    "lr = LR(2)\n",
    "lr.fit(train_data, train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
